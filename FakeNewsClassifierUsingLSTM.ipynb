{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake News Classifier Using LSTM\n",
    "\n",
    "Dataset: https://www.kaggle.com/c/fake-news/data#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Drop Nan Records\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Independent Features\n",
    "\n",
    "X=df.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Dependent features\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vocabulary size\n",
    "voc_size=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onehot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ever get the feeling your life circles the roundabout rather than heads in a straight line toward the intended destination? [Hillary Clinton remains the big woman on campus in leafy, liberal Wellesley, Massachusetts. Everywhere else votes her most likely to don her inauguration dress for the remainder of her days the way Miss Havisham forever wore that wedding dress.  Speaking of Great Expectations, Hillary Rodham overflowed with them 48 years ago when she first addressed a Wellesley graduating class. The president of the college informed those gathered in 1969 that the students needed “no debate so far as I could ascertain as to who their spokesman was to be” (kind of the like the Democratic primaries in 2016 minus the   terms unknown then even at a Seven Sisters school). “I am very glad that Miss Adams made it clear that what I am speaking for today is all of us —  the 400 of us,” Miss Rodham told her classmates. After appointing herself Edger Bergen to the Charlie McCarthys and Mortimer Snerds in attendance, the    bespectacled in granny glasses (awarding her matronly wisdom —  or at least John Lennon wisdom) took issue with the previous speaker. Despite becoming the first   to win election to a seat in the U. S. Senate since Reconstruction, Edward Brooke came in for criticism for calling for “empathy” for the goals of protestors as he criticized tactics. Though Clinton in her senior thesis on Saul Alinsky lamented “Black Power demagogues” and “elitist arrogance and repressive intolerance” within the New Left, similar words coming out of a Republican necessitated a brief rebuttal. “Trust,” Rodham ironically observed in 1969, “this is one word that when I asked the class at our rehearsal what it was they wanted me to say for them, everyone came up to me and said ‘Talk about trust, talk about the lack of trust both for us and the way we feel about others. Talk about the trust bust.’ What can you say about it? What can you say about a feeling that permeates a generation and that perhaps is not even understood by those who are distrusted?” The “trust bust” certainly busted Clinton’s 2016 plans. She certainly did not even understand that people distrusted her. After Whitewater, Travelgate, the vast   conspiracy, Benghazi, and the missing emails, Clinton found herself the distrusted voice on Friday. There was a load of compromising on the road to the broadening of her political horizons. And distrust from the American people —  Trump edged her 48 percent to 38 percent on the question immediately prior to November’s election —  stood as a major reason for the closing of those horizons. Clinton described her vanquisher and his supporters as embracing a “lie,” a “con,” “alternative facts,” and “a   assault on truth and reason. ” She failed to explain why the American people chose his lies over her truth. “As the history majors among you here today know all too well, when people in power invent their own facts and attack those who question them, it can mark the beginning of the end of a free society,” she offered. “That is not hyperbole. ” Like so many people to emerge from the 1960s, Hillary Clinton embarked upon a long, strange trip. From high school Goldwater Girl and Wellesley College Republican president to Democratic politician, Clinton drank in the times and the place that gave her a degree. More significantly, she went from idealist to cynic, as a comparison of her two Wellesley commencement addresses show. Way back when, she lamented that “for too long our leaders have viewed politics as the art of the possible, and the challenge now is to practice politics as the art of making what appears to be impossible possible. ” Now, as the big woman on campus but the odd woman out of the White House, she wonders how her current station is even possible. “Why aren’t I 50 points ahead?” she asked in September. In May she asks why she isn’t president. The woman famously dubbed a “congenital liar” by Bill Safire concludes that lies did her in —  theirs, mind you, not hers. Getting stood up on Election Day, like finding yourself the jilted bride on your wedding day, inspires dangerous delusions.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Xavier\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset Preprocessing\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    #print(i)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hous dem aid even see comey letter jason chaffetz tweet darrel lucu octob subscrib jason chaffetz stump american fork utah imag courtesi michael jolley avail creativ common licens apolog keith olbermann doubt worst person world week fbi director jame comey accord hous democrat aid look like also know second worst person well turn comey sent infam letter announc fbi look email may relat hillari clinton email server rank democrat relev committe hear comey found via tweet one republican committe chairmen know comey notifi republican chairmen democrat rank member hous intellig judiciari oversight committe agenc review email recent discov order see contain classifi inform long letter went oversight committe chairman jason chaffetz set polit world ablaz tweet fbi dir inform fbi learn exist email appear pertin investig case reopen jason chaffetz jasoninthehous octob cours know case comey actual say review email light unrel case know anthoni weiner sext teenag appar littl thing fact matter chaffetz utah republican alreadi vow initi raft investig hillari win least two year worth possibl entir term worth appar chaffetz thought fbi alreadi work result tweet briefli roil nation cooler head realiz dud accord senior hous democrat aid misread letter may least chaffetz sin aid told shareblu boss democrat even know comey letter time found check twitter democrat rank member relev committe receiv comey letter republican chairmen fact democrat rank member receiv chairman oversight govern reform committe jason chaffetz tweet made public let see got right fbi director tell chaffetz gop committe chairmen major develop potenti polit explos investig neither chaffetz colleagu courtesi let democrat counterpart know instead accord aid made find twitter alreadi talk daili ko comey provid advanc notic letter chaffetz republican give time turn spin machin may make good theater noth far even suggest case noth far suggest comey anyth grossli incompet tone deaf suggest howev chaffetz act way make dan burton darrel issa look like model respons bipartisanship even decenc notifi rank member elijah cum someth explos trampl basic standard fair know grant like chaffetz answer sit ridicul republican district anchor provo orem cook partisan vote index r gave mitt romney punish percent vote moreov republican hous leadership given full support chaffetz plan fish expedit mean turn hot light textbook exampl hous becom republican control also second worst person world darrel lucu darrel someth graduat univers north carolina consid journalist old school attempt turn member religi right colleg succeed turn religi right worst nightmar charismat christian unapologet liber desir stand scare silenc increas surviv abus three year marriag may know daili ko christian dem nc follow twitter darrelllucu connect facebook click buy darrel mello yello connect'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2582,\n",
       " 4402,\n",
       " 2004,\n",
       " 1389,\n",
       " 4576,\n",
       " 1346,\n",
       " 1096,\n",
       " 206,\n",
       " 4452,\n",
       " 3155,\n",
       " 134,\n",
       " 370,\n",
       " 2873,\n",
       " 887,\n",
       " 206,\n",
       " 4452,\n",
       " 3507,\n",
       " 264,\n",
       " 2834,\n",
       " 842,\n",
       " 2245,\n",
       " 220,\n",
       " 4428,\n",
       " 3750,\n",
       " 773,\n",
       " 136,\n",
       " 3355,\n",
       " 3498,\n",
       " 1379,\n",
       " 904,\n",
       " 1718,\n",
       " 1663,\n",
       " 827,\n",
       " 3444,\n",
       " 3224,\n",
       " 561,\n",
       " 1364,\n",
       " 1764,\n",
       " 3331,\n",
       " 1346,\n",
       " 624,\n",
       " 2582,\n",
       " 4262,\n",
       " 2004,\n",
       " 2126,\n",
       " 4369,\n",
       " 3268,\n",
       " 2296,\n",
       " 3054,\n",
       " 827,\n",
       " 3444,\n",
       " 219,\n",
       " 2742,\n",
       " 1346,\n",
       " 4133,\n",
       " 3341,\n",
       " 1096,\n",
       " 1905,\n",
       " 1364,\n",
       " 2126,\n",
       " 2232,\n",
       " 491,\n",
       " 229,\n",
       " 4758,\n",
       " 948,\n",
       " 2232,\n",
       " 2448,\n",
       " 3632,\n",
       " 4262,\n",
       " 1213,\n",
       " 3596,\n",
       " 239,\n",
       " 1346,\n",
       " 4981,\n",
       " 2811,\n",
       " 3155,\n",
       " 3321,\n",
       " 1152,\n",
       " 3596,\n",
       " 4723,\n",
       " 2296,\n",
       " 1346,\n",
       " 4183,\n",
       " 1152,\n",
       " 4723,\n",
       " 4262,\n",
       " 3632,\n",
       " 1282,\n",
       " 2582,\n",
       " 989,\n",
       " 1694,\n",
       " 614,\n",
       " 3596,\n",
       " 1053,\n",
       " 1438,\n",
       " 2232,\n",
       " 2729,\n",
       " 233,\n",
       " 3995,\n",
       " 4576,\n",
       " 2138,\n",
       " 2962,\n",
       " 3776,\n",
       " 963,\n",
       " 1096,\n",
       " 3162,\n",
       " 614,\n",
       " 3596,\n",
       " 1753,\n",
       " 206,\n",
       " 4452,\n",
       " 2584,\n",
       " 2367,\n",
       " 3224,\n",
       " 3299,\n",
       " 3155,\n",
       " 1364,\n",
       " 716,\n",
       " 3776,\n",
       " 1364,\n",
       " 132,\n",
       " 488,\n",
       " 2232,\n",
       " 3825,\n",
       " 911,\n",
       " 2073,\n",
       " 853,\n",
       " 2689,\n",
       " 206,\n",
       " 4452,\n",
       " 498,\n",
       " 2873,\n",
       " 2644,\n",
       " 2296,\n",
       " 853,\n",
       " 1346,\n",
       " 4695,\n",
       " 4983,\n",
       " 1438,\n",
       " 2232,\n",
       " 1306,\n",
       " 1464,\n",
       " 853,\n",
       " 2296,\n",
       " 831,\n",
       " 4794,\n",
       " 1774,\n",
       " 349,\n",
       " 666,\n",
       " 4642,\n",
       " 1348,\n",
       " 1478,\n",
       " 541,\n",
       " 4452,\n",
       " 842,\n",
       " 1152,\n",
       " 842,\n",
       " 1115,\n",
       " 444,\n",
       " 751,\n",
       " 2073,\n",
       " 4758,\n",
       " 2980,\n",
       " 4687,\n",
       " 363,\n",
       " 109,\n",
       " 4941,\n",
       " 4765,\n",
       " 469,\n",
       " 4331,\n",
       " 4941,\n",
       " 666,\n",
       " 4452,\n",
       " 2670,\n",
       " 1364,\n",
       " 842,\n",
       " 4830,\n",
       " 91,\n",
       " 3155,\n",
       " 2491,\n",
       " 565,\n",
       " 2909,\n",
       " 54,\n",
       " 2679,\n",
       " 4480,\n",
       " 2858,\n",
       " 624,\n",
       " 2572,\n",
       " 2582,\n",
       " 4262,\n",
       " 2004,\n",
       " 3000,\n",
       " 1096,\n",
       " 491,\n",
       " 4687,\n",
       " 4452,\n",
       " 454,\n",
       " 2004,\n",
       " 2123,\n",
       " 4821,\n",
       " 3201,\n",
       " 4262,\n",
       " 1389,\n",
       " 2296,\n",
       " 1346,\n",
       " 1096,\n",
       " 3101,\n",
       " 4981,\n",
       " 2025,\n",
       " 2813,\n",
       " 4262,\n",
       " 3632,\n",
       " 1282,\n",
       " 1213,\n",
       " 3596,\n",
       " 3781,\n",
       " 1346,\n",
       " 1096,\n",
       " 1152,\n",
       " 4723,\n",
       " 1478,\n",
       " 4262,\n",
       " 3632,\n",
       " 1282,\n",
       " 3781,\n",
       " 1753,\n",
       " 614,\n",
       " 2463,\n",
       " 1725,\n",
       " 3596,\n",
       " 206,\n",
       " 4452,\n",
       " 3155,\n",
       " 4083,\n",
       " 3858,\n",
       " 1392,\n",
       " 4576,\n",
       " 3652,\n",
       " 4472,\n",
       " 1364,\n",
       " 1764,\n",
       " 3731,\n",
       " 4452,\n",
       " 1247,\n",
       " 3596,\n",
       " 4723,\n",
       " 4541,\n",
       " 1044,\n",
       " 3603,\n",
       " 2367,\n",
       " 3005,\n",
       " 2073,\n",
       " 4365,\n",
       " 4452,\n",
       " 2712,\n",
       " 220,\n",
       " 1392,\n",
       " 4262,\n",
       " 4277,\n",
       " 2296,\n",
       " 3575,\n",
       " 624,\n",
       " 2004,\n",
       " 4083,\n",
       " 4028,\n",
       " 2813,\n",
       " 842,\n",
       " 622,\n",
       " 261,\n",
       " 2660,\n",
       " 1346,\n",
       " 4152,\n",
       " 981,\n",
       " 4635,\n",
       " 1096,\n",
       " 4452,\n",
       " 1152,\n",
       " 3816,\n",
       " 3101,\n",
       " 2742,\n",
       " 1948,\n",
       " 3456,\n",
       " 491,\n",
       " 155,\n",
       " 696,\n",
       " 182,\n",
       " 4354,\n",
       " 3811,\n",
       " 1389,\n",
       " 2679,\n",
       " 853,\n",
       " 4354,\n",
       " 3811,\n",
       " 2679,\n",
       " 1346,\n",
       " 4508,\n",
       " 4735,\n",
       " 466,\n",
       " 2822,\n",
       " 2931,\n",
       " 2679,\n",
       " 683,\n",
       " 4452,\n",
       " 1944,\n",
       " 3162,\n",
       " 155,\n",
       " 2376,\n",
       " 1275,\n",
       " 134,\n",
       " 4597,\n",
       " 2126,\n",
       " 4369,\n",
       " 4375,\n",
       " 4084,\n",
       " 2148,\n",
       " 1389,\n",
       " 2101,\n",
       " 4183,\n",
       " 3632,\n",
       " 1282,\n",
       " 795,\n",
       " 1479,\n",
       " 1390,\n",
       " 3005,\n",
       " 1158,\n",
       " 2321,\n",
       " 1246,\n",
       " 2381,\n",
       " 2296,\n",
       " 2247,\n",
       " 4369,\n",
       " 4452,\n",
       " 1089,\n",
       " 3491,\n",
       " 120,\n",
       " 1152,\n",
       " 4972,\n",
       " 4639,\n",
       " 4593,\n",
       " 4545,\n",
       " 3239,\n",
       " 4058,\n",
       " 1138,\n",
       " 4717,\n",
       " 3848,\n",
       " 814,\n",
       " 3638,\n",
       " 3627,\n",
       " 2525,\n",
       " 1814,\n",
       " 1138,\n",
       " 2100,\n",
       " 1152,\n",
       " 2582,\n",
       " 4394,\n",
       " 2270,\n",
       " 3790,\n",
       " 4025,\n",
       " 4452,\n",
       " 2094,\n",
       " 470,\n",
       " 4407,\n",
       " 315,\n",
       " 2742,\n",
       " 2082,\n",
       " 1306,\n",
       " 2712,\n",
       " 746,\n",
       " 2582,\n",
       " 953,\n",
       " 1152,\n",
       " 2810,\n",
       " 3268,\n",
       " 3054,\n",
       " 827,\n",
       " 3444,\n",
       " 3224,\n",
       " 134,\n",
       " 370,\n",
       " 134,\n",
       " 1390,\n",
       " 2610,\n",
       " 426,\n",
       " 1605,\n",
       " 502,\n",
       " 4624,\n",
       " 160,\n",
       " 109,\n",
       " 3578,\n",
       " 3719,\n",
       " 2742,\n",
       " 1282,\n",
       " 132,\n",
       " 4472,\n",
       " 3297,\n",
       " 747,\n",
       " 2742,\n",
       " 132,\n",
       " 4472,\n",
       " 827,\n",
       " 2329,\n",
       " 2521,\n",
       " 3830,\n",
       " 3586,\n",
       " 2674,\n",
       " 4777,\n",
       " 2162,\n",
       " 2335,\n",
       " 3906,\n",
       " 978,\n",
       " 1529,\n",
       " 2013,\n",
       " 3721,\n",
       " 109,\n",
       " 1380,\n",
       " 491,\n",
       " 2296,\n",
       " 261,\n",
       " 2660,\n",
       " 3830,\n",
       " 4402,\n",
       " 939,\n",
       " 545,\n",
       " 2813,\n",
       " 4754,\n",
       " 203,\n",
       " 3055,\n",
       " 1431,\n",
       " 3947,\n",
       " 134,\n",
       " 3060,\n",
       " 2582,\n",
       " 203]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n",
    "onehot_repr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 109 1380  491 ... 3060 2582  203]\n",
      " [4127 1719  531 ... 3827 4291  267]\n",
      " [2789 2923 2389 ... 4262 4918  764]\n",
      " ...\n",
      " [3939  482 3882 ... 2772 1148 1238]\n",
      " [1711 1144 2463 ... 2169 2097 3614]\n",
      " [ 869 3468  183 ... 2925 1350 4088]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=20\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 109, 1380,  491, 2296,  261, 2660, 3830, 4402,  939,  545, 2813,\n",
       "       4754,  203, 3055, 1431, 3947,  134, 3060, 2582,  203])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 40)            200000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Creating model\n",
    "embedding_vector_features=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, (18285,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_docs),y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18285, 20), (18285,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape,y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4262 - accuracy: 0.7843 - val_loss: 0.3333 - val_accuracy: 0.8497\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.2480 - accuracy: 0.8970 - val_loss: 0.3371 - val_accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.1892 - accuracy: 0.9272 - val_loss: 0.3554 - val_accuracy: 0.8489\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.1371 - accuracy: 0.9515 - val_loss: 0.4189 - val_accuracy: 0.8391\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0994 - accuracy: 0.9645 - val_loss: 0.4814 - val_accuracy: 0.8365\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0651 - accuracy: 0.9776 - val_loss: 0.5919 - val_accuracy: 0.8366\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 0.7002 - val_accuracy: 0.8247\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 0.8251 - val_accuracy: 0.8222\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.9481 - val_accuracy: 0.8268\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 1.1485 - val_accuracy: 0.8194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21bc690cec8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Finally Training\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "## Creating model\n",
    "embedding_vector_features=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics And Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-66f7fe571d01>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2789,  630],\n",
       "       [ 460, 2156]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8193869096934548"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
